import streamlit as st
import json
import datetime
import requests
import math

# ... [å…¶ä»–å‡½æ•¸ä¿æŒä¸è®Š] ...

def display_entries(data, journal_urls, items_per_page=10):
    """é¡¯ç¤ºæ‰€æœ‰é¸ä¸­æœŸåˆŠçš„æ¢ç›®ï¼Œå¸¶åˆ†é åŠŸèƒ½"""
    all_entries = []
    for feed_name, feed_data in data.items():
        all_entries.extend([(entry, feed_name) for entry in feed_data['entries']])
    
    all_entries.sort(key=lambda x: x[0]['published'], reverse=True)
    
    total_entries = len(all_entries)
    total_pages = max(1, math.ceil(total_entries / items_per_page))

    if 'current_page' not in st.session_state:
        st.session_state.current_page = 1

    st.session_state.current_page = min(st.session_state.current_page, total_pages)

    start_idx = (st.session_state.current_page - 1) * items_per_page
    end_idx = min(start_idx + items_per_page, total_entries)
    
    entries_container = st.container()
    
    if total_entries > 0:
        with entries_container:
            for i, (entry, feed_name) in enumerate(all_entries[start_idx:end_idx], start=1):
                with st.expander(f"ğŸ“ **{entry['title']}**\n*{entry['title_translated']}*", key=f"expander_{st.session_state.current_page}_{i}"):
                    st.write(f"ç™¼å¸ƒæ—¥æœŸ: {entry['published']}")
                    st.markdown(entry['tldr'])
                    journal_url = journal_urls.get(feed_name, "#")
                    if journal_url != "#":
                        st.markdown(f"ğŸ”— [PubMed]({entry['link']}) ğŸ“š [{feed_name}]({journal_url})")
                    else:
                        st.markdown(f"ğŸ”— [PubMed]({entry['link']}) ğŸ“š {feed_name}")

        st.write("---")
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            def change_page():
                st.session_state.current_page = st.session_state.new_page
                st.rerun()

            st.number_input(
                f"é ç¢¼ (å…± {total_pages} é )",
                min_value=1,
                max_value=total_pages,
                value=st.session_state.current_page,
                step=1,
                key="new_page",
                on_change=change_page
            )
    else:
        st.write("æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„æ–‡ç« ã€‚")

def main():
    st.set_page_config(page_title="è½èªæœŸåˆŠé€Ÿå ±", page_icon="ğŸ“š", layout="wide")

    if 'current_page' not in st.session_state:
        st.session_state.current_page = 1
    if 'previous_search' not in st.session_state:
        st.session_state.previous_search = ""
    if 'previous_feeds' not in st.session_state:
        st.session_state.previous_feeds = []

    github_repo = "xxcyl/rss-feed-processor"
    file_path = "rss_data_bilingual.json"
    
    data = load_json_data_from_github(github_repo, file_path)
    if data is None:
        return
    
    # åŠ è¼‰æœŸåˆŠé…ç½®
    with open('journal_config.json', 'r', encoding='utf-8') as f:
        journal_config = json.load(f)
    
    # å‰µå»ºæœŸåˆŠåç¨±åˆ° URL çš„æ˜ å°„
    journal_urls = {j['name']: j['url'] for c in journal_config['categories'].values() for j in c}

    # å°‡ä¸»æ¨™é¡Œç§»åˆ° tab ä¸Šæ–¹
    st.title("ğŸ“š è½èªæœŸåˆŠé€Ÿå ±")

    tab1, tab2 = st.tabs(["ğŸ  ä¸»é ", "â„¹ï¸ ç³»çµ±ä»‹ç´¹"])
    
    with tab1:
        # æœç´¢æ¡†ç§»åˆ°ä¸»ç•«é¢æœ€ä¸Šæ–¹
        search_term = st.text_input("ğŸ” æœç´¢æ–‡ç«  (æ¨™é¡Œæˆ–æ‘˜è¦)", "", key="search_input")

        # å´é‚Šæ¬„ï¼šç¯©é¸å™¨
        with st.sidebar:
            st.subheader("æœŸåˆŠé¸æ“‡")
            
            selected_feeds = []
            
            for category, journals in journal_config['categories'].items():
                with st.expander(f"ğŸ“‚ {category}", expanded=True):
                    for journal in journals:
                        if journal['name'] in data:
                            article_count = len(data[journal['name']]['entries'])
                            if st.checkbox(f"{journal['name']} ({article_count})", key=f"checkbox_{journal['name']}"):
                                selected_feeds.append(journal['name'])
            
            all_categorized_journals = [j['name'] for c in journal_config['categories'].values() for j in c]
            uncategorized_journals = [feed for feed in data.keys() if feed not in all_categorized_journals]
            if uncategorized_journals:
                st.warning(f"è­¦å‘Šï¼šä»¥ä¸‹æœŸåˆŠæœªè¢«åˆ†é¡ï¼š{', '.join(uncategorized_journals)}")

        # ä¸»å…§å®¹å€
        if search_term != st.session_state.previous_search or selected_feeds != st.session_state.previous_feeds:
            st.session_state.current_page = 1
            st.session_state.previous_search = search_term
            st.session_state.previous_feeds = selected_feeds

        filtered_data = search_entries(data, search_term, selected_feeds if selected_feeds else None)
        
        if filtered_data:
            total_feeds = len(filtered_data)
            total_articles = sum(len(feed_data['entries']) for feed_data in filtered_data.values())
            
            st.write(f"ğŸ“Š é¡¯ç¤º {total_feeds} å€‹æœŸåˆŠä¸­çš„ {total_articles} ç¯‡æ–‡ç« ")              
            display_entries(filtered_data, journal_urls)
        else:
            st.write("æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„æ–‡ç« ã€‚")
    
    with tab2:
        show_introduction()

if __name__ == "__main__":
    main()
