import streamlit as st
import json
import datetime
import requests
import math

def load_json_data_from_github(repo, file_path):
    """å¾ GitHub åŠ è¼‰ JSON æ•¸æ“š"""
    url = f"https://raw.githubusercontent.com/{repo}/main/{file_path}"
    response = requests.get(url)
    if response.status_code == 200:
        return json.loads(response.text)
    else:
        st.error(f"Failed to load data from GitHub. Status code: {response.status_code}")
        return None

def search_entries(data, search_term, selected_feeds):
    """æœç´¢æŒ‡å®š feed ä¸­ç¬¦åˆé—œéµå­—çš„æ¢ç›®"""
    result = {}
    search_term = search_term.lower() if search_term else ""
    
    for feed_name, feed_data in data.items():
        if selected_feeds and feed_name not in selected_feeds:
            continue
        
        filtered_entries = [
            entry for entry in feed_data['entries']
            if not search_term or
            search_term in entry['title'].lower() or
            search_term in entry['title_translated'].lower() or
            search_term in entry['tldr'].lower()
        ]
        
        if filtered_entries:
            result[feed_name] = {
                'feed_title': feed_data['feed_title'],
                'feed_link': feed_data['feed_link'],
                'feed_updated': feed_data['feed_updated'],
                'entries': filtered_entries
            }
    
    return result

def display_entries(data, items_per_page=10):
    """é¡¯ç¤ºæ‰€æœ‰é¸ä¸­ feed çš„æ¢ç›®ï¼Œå¸¶åˆ†é åŠŸèƒ½"""
    all_entries = []
    for feed_name, feed_data in data.items():
        all_entries.extend([(entry, feed_name) for entry in feed_data['entries']])
    
    all_entries.sort(key=lambda x: x[0]['published'], reverse=True)
    
    total_entries = len(all_entries)
    total_pages = max(1, math.ceil(total_entries / items_per_page))

    # ç¢ºä¿ç•¶å‰é ç¢¼ä¸è¶…éç¸½é æ•¸
    st.session_state.current_page = min(st.session_state.current_page, total_pages)

    # è¨ˆç®—ç•¶å‰é çš„æ–‡ç« ç¯„åœ
    start_idx = (st.session_state.current_page - 1) * items_per_page
    end_idx = min(start_idx + items_per_page, total_entries)
    
    if total_entries > 0:
        st.write(f"é¡¯ç¤ºç¬¬ {start_idx + 1} åˆ° {end_idx} ç¯‡æ–‡ç« ")
    
        # é¡¯ç¤ºç•¶å‰é çš„æ–‡ç« 
        for entry, feed_name in all_entries[start_idx:end_idx]:
            with st.expander(f"**{entry['title']}**\n*{entry['title_translated']}* (ä¾†è‡ª: {feed_name})"):
                st.write(f"Published: {entry['published']}")
                st.markdown(entry['tldr'])
                st.markdown(f"[PubMed]({entry['link']})")

        # åº•éƒ¨åˆ†é æ§ä»¶
        st.write("---")
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            page = st.number_input(f"é ç¢¼ (å…± {total_pages} é )", min_value=1, max_value=total_pages, value=st.session_state.current_page, step=1, key="page_number")
        
        # å¦‚æœé ç¢¼æ”¹è®Šï¼Œæ›´æ–° session_state
        if page != st.session_state.current_page:
            st.session_state.current_page = page
            st.experimental_rerun()
    else:
        st.write("æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„æ–‡ç« ã€‚")

def main():
    st.set_page_config(page_title="è½åŠ›æœŸåˆŠé€Ÿå ±", page_icon="ğŸ“š", layout="wide")
    st.title("ğŸ“š è½åŠ›æœŸåˆŠé€Ÿå ±")

    # åˆå§‹åŒ– session_state
    if 'current_page' not in st.session_state:
        st.session_state.current_page = 1
    if 'previous_search' not in st.session_state:
        st.session_state.previous_search = ""
    if 'previous_feeds' not in st.session_state:
        st.session_state.previous_feeds = []

    github_repo = "xxcyl/rss-feed-processor"
    file_path = "rss_data_bilingual.json"
    
    data = load_json_data_from_github(github_repo, file_path)
    if data is None:
        return
    
    # å´é‚Šæ¬„ï¼šç¯©é¸å™¨
    with st.sidebar:
        # æœç´¢æ¡†ç§»åˆ°æœ€ä¸Šæ–¹
        search_term = st.text_input("æœç´¢æ–‡ç«  (æ¨™é¡Œæˆ–æ‘˜è¦)", "")
        
        # å°‡ feed åç¨±æŒ‰å­—æ¯é †åºæ’åº
        feed_names = sorted(list(data.keys()))
        
        # ä½¿ç”¨ checkbox ä¾†é¸æ“‡ feed
        selected_feeds = []
        for feed in feed_names:
            if st.checkbox(feed, key=feed):
                selected_feeds.append(feed)

    # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡ç½®é ç¢¼
    if search_term != st.session_state.previous_search or selected_feeds != st.session_state.previous_feeds:
        st.session_state.current_page = 1
        st.session_state.previous_search = search_term
        st.session_state.previous_feeds = selected_feeds

    # ä¸»å…§å®¹å€
    filtered_data = search_entries(data, search_term, selected_feeds if selected_feeds else None)
    
    if filtered_data:
        total_feeds = len(filtered_data)
        total_articles = sum(len(feed_data['entries']) for feed_data in filtered_data.values())
        
        # åœ¨å´é‚Šæ¬„æœç´¢æ¡†ä¸‹æ–¹é¡¯ç¤ºæ–‡ç« çµ±è¨ˆä¿¡æ¯
        with st.sidebar:
            st.write(f"é¡¯ç¤º {total_feeds} å€‹ feed ä¸­çš„ {total_articles} ç¯‡æ–‡ç« ")
            st.write("---")  # åˆ†éš”ç·š
        
        display_entries(filtered_data)
    else:
        st.write("æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„æ–‡ç« ã€‚")

if __name__ == "__main__":
    main()
